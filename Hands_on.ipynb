{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54078597-d50f-4287-9cf5-3e79f1565015",
   "metadata": {},
   "source": [
    "# NVIDIA DeepStream Hands-On\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Config-based execution (gst-launch, deepstream-app)\n",
    "- nvinferserver\n",
    "- Major plugins & deepstream-test-1-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432d399-e2f1-4ad5-9205-76f521c52660",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /opt/nvidia/deepstream/deepstream-6.1/samples && bash prepare_ds_triton_model_repo.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b2f5e0-0327-47ee-a842-21bed850d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gst-inspect-1.0 nvinferserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a8d09-23c9-4465-b229-1df85e0bc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gst-launch-1.0 filesrc location=/opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.mp4 ! qtdemux ! h264parse ! nvv4l2decoder \\\n",
    "! m.sink_0 nvstreammux name=m batch-size=1 width=360 height=240 ! nvinfer config-file-path=/opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app/config_infer_primary.txt \\\n",
    "batch-size=1 unique-id=1 ! nvtracker ll-lib-file=/opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so \\\n",
    "! nvmultistreamtiler rows=1 columns=1 width=360 height=240 ! nvvideoconvert ! nvdsosd ! nvvideoconvert ! nvv4l2h264enc ! h264parse ! qtmux ! filesink location=out.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4baf019-0dc5-4d37-b92a-862c0a9f08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"out.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d23091-fdf6-4de9-ba17-38c7c7c719cd",
   "metadata": {},
   "source": [
    "<img src=\"img/nvinferserver_supportmatrix.png\" alt=\"SupportMatrix\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58982b13-83c0-43d3-80bb-e06a1f6abfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gst-launch-1.0 filesrc location=/opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.mp4 ! qtdemux ! h264parse ! nvv4l2decoder \\\n",
    "! m.sink_0 nvstreammux name=m batch-size=1 width=360 height=240 \\\n",
    "! nvinferserver config-file-path=/opt/nvidia/deepstream/deepstream-6.1/samples/configs/deepstream-app-triton/config_infer_primary_detector_ssd_mobilenet_v1_coco_2018_01_28.txt \\\n",
    "! nvtracker ll-lib-file=/opt/nvidia/deepstream/deepstream/lib/libnvds_nvmultiobjecttracker.so \\\n",
    "! nvmultistreamtiler rows=1 columns=1 width=360 height=240 ! nvvideoconvert ! nvdsosd ! nvvideoconvert ! nvv4l2h264enc ! h264parse ! qtmux ! filesink location=out_triton.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a964f6c-34b2-42c3-96a7-6f02869f1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"out_triton.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd488bc-f73c-4f35-b612-bdc80599741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /opt/nvidia/deepstream/deepstream/samples/configs/deepstream-app-triton/config_infer_primary_detector_ssd_mobilenet_v1_coco_2018_01_28.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb05b3a7-c7bb-4e90-953e-035afc34aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /opt/nvidia/deepstream/deepstream/samples/triton_model_repo/ssd_mobilenet_v1_coco_2018_01_28/config.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f1faa-ce0c-4479-9e00-a495eada21e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /opt/nvidia/deepstream/deepstream-6.1/sources/libs/nvdsinfer_customparser/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b7bcd-646e-4135-b8f1-8407b83d7ffd",
   "metadata": {},
   "source": [
    "![nn](img/deepstream_app.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25a143-136a-445e-a3b4-34e97c01e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "!deepstream-app -c /opt/nvidia/deepstream/deepstream-6.1/workspace/deepstream_app_triton_config.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b690cc5-a5fe-4184-8868-1f6f27152f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"out_deepstream_app.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba88d1-d886-4f7d-876c-ca5269807e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /opt/nvidia/deepstream/deepstream-6.1/workspace/deepstream_app_triton_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf9306-f365-4074-b4f2-69d4091dc633",
   "metadata": {},
   "source": [
    "## NVIDIA DeepStream Plugins\n",
    "\n",
    "### Nvstreammux\n",
    "\n",
    "The Gst-nvstreammux plugin forms a batch of frames from multiple input sources.\n",
    "\n",
    "![NVSTREAMMUX](img/nvstreammux.png)\n",
    "\n",
    "### Nvinfer\n",
    "\n",
    "The nvinfer plugin provides [TensorRT](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html)-based inference for detection and tracking. The lowlevel library (libnvds_infer) operates either on float RGB or BGR planar data with dimensions of Network Height and Network Width. The plugin accepts NV12/RGBA data from upstream components like the decoder, muxer, and dewarper.\n",
    "The Gst-nvinfer plugin also performs preprocessing operations like format conversion, scaling, mean subtraction, and produces final float RGB/BGR planar data which is passed to the low-level library. The low-level library uses the TensorRT engine for inferencing. It outputs each classified object’s class and each detected object’s bounding boxes (Bboxes) after clustering.\n",
    "\n",
    "![NVINFER](img/nvinfer.png)\n",
    "\n",
    "\n",
    "### Nvosd\n",
    "\n",
    "The nvosd plugin draws bounding boxes, text, and RoI (Regions of Interest) polygons (Polygons are presented as a set of lines). The plugin accepts an RGBA buffer with attached metadata from the upstream component. It\n",
    "draws bounding boxes, which may be shaded depending on the configuration (e.g. width, color, and opacity) of a given bounding box. It also draws text and RoI polygons at specified locations in the frame. Text and polygon parameters are configurable through metadata.\n",
    "\n",
    "![NVOSD](img/nvdsosd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa8eef0-5f3f-48a0-8dbd-b9956898427d",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "<img src=\"img/metadata.png\" alt=\"DS Meta\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce45550-7ae7-4a7d-9a58-3060260058b2",
   "metadata": {},
   "source": [
    "<img src=\"img/metadata2.png\" alt=\"DS Meta\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371653d-3435-4829-af3a-2210949ed1f4",
   "metadata": {},
   "source": [
    "<img src=\"img/deepstream_test1_app.png\" alt=\"Example\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c020469d-7009-4ce7-8870-7d5c30b5fd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*\n",
      " * Copyright (c) 2018-2022, NVIDIA CORPORATION. All rights reserved.\n",
      " *\n",
      " * Permission is hereby granted, free of charge, to any person obtaining a\n",
      " * copy of this software and associated documentation files (the \"Software\"),\n",
      " * to deal in the Software without restriction, including without limitation\n",
      " * the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
      " * and/or sell copies of the Software, and to permit persons to whom the\n",
      " * Software is furnished to do so, subject to the following conditions:\n",
      " *\n",
      " * The above copyright notice and this permission notice shall be included in\n",
      " * all copies or substantial portions of the Software.\n",
      " *\n",
      " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL\n",
      " * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
      " * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
      " * DEALINGS IN THE SOFTWARE.\n",
      " */\n",
      "\n",
      "#include <gst/gst.h>\n",
      "#include <glib.h>\n",
      "#include <stdio.h>\n",
      "#include <cuda_runtime_api.h>\n",
      "#include \"gstnvdsmeta.h\"\n",
      "#include \"nvds_yml_parser.h\"\n",
      "\n",
      "#define MAX_DISPLAY_LEN 64\n",
      "\n",
      "#define PGIE_CLASS_ID_VEHICLE 0\n",
      "#define PGIE_CLASS_ID_PERSON 2\n",
      "\n",
      "/* The muxer output resolution must be set if the input streams will be of\n",
      " * different resolution. The muxer will scale all the input frames to this\n",
      " * resolution. */\n",
      "#define MUXER_OUTPUT_WIDTH 1920\n",
      "#define MUXER_OUTPUT_HEIGHT 1080\n",
      "\n",
      "/* Muxer batch formation timeout, for e.g. 40 millisec. Should ideally be set\n",
      " * based on the fastest source's framerate. */\n",
      "#define MUXER_BATCH_TIMEOUT_USEC 40000\n",
      "\n",
      "gint frame_number = 0;\n",
      "gchar pgie_classes_str[4][32] = { \"Vehicle\", \"TwoWheeler\", \"Person\",\n",
      "  \"Roadsign\"\n",
      "};\n",
      "\n",
      "/* osd_sink_pad_buffer_probe  will extract metadata received on OSD sink pad\n",
      " * and update params for drawing rectangle, object information etc. */\n",
      "\n",
      "static GstPadProbeReturn\n",
      "osd_sink_pad_buffer_probe (GstPad * pad, GstPadProbeInfo * info,\n",
      "    gpointer u_data)\n",
      "{\n",
      "    GstBuffer *buf = (GstBuffer *) info->data;\n",
      "    guint num_rects = 0; \n",
      "    NvDsObjectMeta *obj_meta = NULL;\n",
      "    guint vehicle_count = 0;\n",
      "    guint person_count = 0;\n",
      "    NvDsMetaList * l_frame = NULL;\n",
      "    NvDsMetaList * l_obj = NULL;\n",
      "    NvDsDisplayMeta *display_meta = NULL;\n",
      "\n",
      "    NvDsBatchMeta *batch_meta = gst_buffer_get_nvds_batch_meta (buf);\n",
      "\n",
      "    for (l_frame = batch_meta->frame_meta_list; l_frame != NULL;\n",
      "      l_frame = l_frame->next) {\n",
      "        NvDsFrameMeta *frame_meta = (NvDsFrameMeta *) (l_frame->data);\n",
      "        int offset = 0;\n",
      "        for (l_obj = frame_meta->obj_meta_list; l_obj != NULL;\n",
      "                l_obj = l_obj->next) {\n",
      "            obj_meta = (NvDsObjectMeta *) (l_obj->data);\n",
      "            if (obj_meta->class_id == PGIE_CLASS_ID_VEHICLE) {\n",
      "                vehicle_count++;\n",
      "                num_rects++;\n",
      "            }\n",
      "            if (obj_meta->class_id == PGIE_CLASS_ID_PERSON) {\n",
      "                person_count++;\n",
      "                num_rects++;\n",
      "            }\n",
      "        }\n",
      "        display_meta = nvds_acquire_display_meta_from_pool(batch_meta);\n",
      "        NvOSD_TextParams *txt_params  = &display_meta->text_params[0];\n",
      "        display_meta->num_labels = 1;\n",
      "        txt_params->display_text = g_malloc0 (MAX_DISPLAY_LEN);\n",
      "        offset = snprintf(txt_params->display_text, MAX_DISPLAY_LEN, \"Person = %d \", person_count);\n",
      "        offset = snprintf(txt_params->display_text + offset , MAX_DISPLAY_LEN, \"Vehicle = %d \", vehicle_count);\n",
      "\n",
      "        /* Now set the offsets where the string should appear */\n",
      "        txt_params->x_offset = 10;\n",
      "        txt_params->y_offset = 12;\n",
      "\n",
      "        /* Font , font-color and font-size */\n",
      "        txt_params->font_params.font_name = \"Serif\";\n",
      "        txt_params->font_params.font_size = 10;\n",
      "        txt_params->font_params.font_color.red = 1.0;\n",
      "        txt_params->font_params.font_color.green = 1.0;\n",
      "        txt_params->font_params.font_color.blue = 1.0;\n",
      "        txt_params->font_params.font_color.alpha = 1.0;\n",
      "\n",
      "        /* Text background color */\n",
      "        txt_params->set_bg_clr = 1;\n",
      "        txt_params->text_bg_clr.red = 0.0;\n",
      "        txt_params->text_bg_clr.green = 0.0;\n",
      "        txt_params->text_bg_clr.blue = 0.0;\n",
      "        txt_params->text_bg_clr.alpha = 1.0;\n",
      "\n",
      "        nvds_add_display_meta_to_frame(frame_meta, display_meta);\n",
      "    }\n",
      "\n",
      "    g_print (\"Frame Number = %d Number of objects = %d \"\n",
      "            \"Vehicle Count = %d Person Count = %d\\n\",\n",
      "            frame_number, num_rects, vehicle_count, person_count);\n",
      "    frame_number++;\n",
      "    return GST_PAD_PROBE_OK;\n",
      "}\n",
      "\n",
      "static gboolean\n",
      "bus_call (GstBus * bus, GstMessage * msg, gpointer data)\n",
      "{\n",
      "  GMainLoop *loop = (GMainLoop *) data;\n",
      "  switch (GST_MESSAGE_TYPE (msg)) {\n",
      "    case GST_MESSAGE_EOS:\n",
      "      g_print (\"End of stream\\n\");\n",
      "      g_main_loop_quit (loop);\n",
      "      break;\n",
      "    case GST_MESSAGE_ERROR:{\n",
      "      gchar *debug;\n",
      "      GError *error;\n",
      "      gst_message_parse_error (msg, &error, &debug);\n",
      "      g_printerr (\"ERROR from element %s: %s\\n\",\n",
      "          GST_OBJECT_NAME (msg->src), error->message);\n",
      "      if (debug)\n",
      "        g_printerr (\"Error details: %s\\n\", debug);\n",
      "      g_free (debug);\n",
      "      g_error_free (error);\n",
      "      g_main_loop_quit (loop);\n",
      "      break;\n",
      "    }\n",
      "    default:\n",
      "      break;\n",
      "  }\n",
      "  return TRUE;\n",
      "}\n",
      "\n",
      "int\n",
      "main (int argc, char *argv[])\n",
      "{\n",
      "  GMainLoop *loop = NULL;\n",
      "  GstElement *pipeline = NULL, *source = NULL, *h264parser = NULL,\n",
      "      *decoder = NULL, *streammux = NULL, *sink = NULL, *pgie = NULL, *nvvidconv = NULL,\n",
      "      *nvosd = NULL;\n",
      "\n",
      "  GstElement *transform = NULL;\n",
      "  GstBus *bus = NULL;\n",
      "  guint bus_watch_id;\n",
      "  GstPad *osd_sink_pad = NULL;\n",
      "\n",
      "  int current_device = -1;\n",
      "  cudaGetDevice(&current_device);\n",
      "  struct cudaDeviceProp prop;\n",
      "  cudaGetDeviceProperties(&prop, current_device);\n",
      "  /* Check input arguments */\n",
      "  if (argc != 2) {\n",
      "    g_printerr (\"Usage: %s <yml file>\\n\", argv[0]);\n",
      "    g_printerr (\"OR: %s <H264 filename>\\n\", argv[0]);\n",
      "    return -1;\n",
      "  }\n",
      "\n",
      "  /* Standard GStreamer initialization */\n",
      "  gst_init (&argc, &argv);\n",
      "  loop = g_main_loop_new (NULL, FALSE);\n",
      "\n",
      "  /* Create gstreamer elements */\n",
      "  /* Create Pipeline element that will form a connection of other elements */\n",
      "  pipeline = gst_pipeline_new (\"dstest1-pipeline\");\n",
      "\n",
      "  /* Source element for reading from the file */\n",
      "  source = gst_element_factory_make (\"filesrc\", \"file-source\");\n",
      "\n",
      "  /* Since the data format in the input file is elementary h264 stream,\n",
      "   * we need a h264parser */\n",
      "  h264parser = gst_element_factory_make (\"h264parse\", \"h264-parser\");\n",
      "\n",
      "  /* Use nvdec_h264 for hardware accelerated decode on GPU */\n",
      "  decoder = gst_element_factory_make (\"nvv4l2decoder\", \"nvv4l2-decoder\");\n",
      "\n",
      "  /* Create nvstreammux instance to form batches from one or more sources. */\n",
      "  streammux = gst_element_factory_make (\"nvstreammux\", \"stream-muxer\");\n",
      "\n",
      "  if (!pipeline || !streammux) {\n",
      "    g_printerr (\"One element could not be created. Exiting.\\n\");\n",
      "    return -1;\n",
      "  }\n",
      "\n",
      "  /* Use nvinfer to run inferencing on decoder's output,\n",
      "   * behaviour of inferencing is set through config file */\n",
      "  pgie = gst_element_factory_make (\"nvinfer\", \"primary-nvinference-engine\");\n",
      "\n",
      "  /* Use convertor to convert from NV12 to RGBA as required by nvosd */\n",
      "  nvvidconv = gst_element_factory_make (\"nvvideoconvert\", \"nvvideo-converter\");\n",
      "\n",
      "  /* Create OSD to draw on the converted RGBA buffer */\n",
      "  nvosd = gst_element_factory_make (\"nvdsosd\", \"nv-onscreendisplay\");\n",
      "\n",
      "  /* Finally render the osd output */\n",
      "  if(prop.integrated) {\n",
      "    transform = gst_element_factory_make (\"nvegltransform\", \"nvegl-transform\");\n",
      "  }\n",
      "  sink = gst_element_factory_make (\"nveglglessink\", \"nvvideo-renderer\");\n",
      "\n",
      "  if (!source || !h264parser || !decoder || !pgie\n",
      "      || !nvvidconv || !nvosd || !sink) {\n",
      "    g_printerr (\"One element could not be created. Exiting.\\n\");\n",
      "    return -1;\n",
      "  }\n",
      "\n",
      "  if(!transform && prop.integrated) {\n",
      "    g_printerr (\"One tegra element could not be created. Exiting.\\n\");\n",
      "    return -1;\n",
      "  }\n",
      "\n",
      "  /* we set the input filename to the source element */\n",
      "  g_object_set (G_OBJECT (source), \"location\", argv[1], NULL);\n",
      "\n",
      "  if (g_str_has_suffix (argv[1], \".h264\")) {\n",
      "    g_object_set (G_OBJECT (source), \"location\", argv[1], NULL);\n",
      "\n",
      "    g_object_set (G_OBJECT (streammux), \"batch-size\", 1, NULL);\n",
      "\n",
      "    g_object_set (G_OBJECT (streammux), \"width\", MUXER_OUTPUT_WIDTH, \"height\",\n",
      "        MUXER_OUTPUT_HEIGHT,\n",
      "        \"batched-push-timeout\", MUXER_BATCH_TIMEOUT_USEC, NULL);\n",
      "\n",
      "    /* Set all the necessary properties of the nvinfer element,\n",
      "     * the necessary ones are : */\n",
      "    g_object_set (G_OBJECT (pgie),\n",
      "        \"config-file-path\", \"dstest1_pgie_config.txt\", NULL);\n",
      "  }\n",
      "\n",
      "  if (g_str_has_suffix (argv[1], \".yml\") || g_str_has_suffix (argv[1], \".yaml\")) {\n",
      "\n",
      "    nvds_parse_file_source(source, argv[1],\"source\");\n",
      "    nvds_parse_streammux(streammux, argv[1],\"streammux\");\n",
      "\n",
      "    /* Set all the necessary properties of the nvinfer element,\n",
      "     * the necessary ones are : */\n",
      "    g_object_set (G_OBJECT (pgie),\n",
      "        \"config-file-path\", \"dstest1_pgie_config.yml\", NULL);\n",
      "  }\n",
      "\n",
      "  /* we add a message handler */\n",
      "  bus = gst_pipeline_get_bus (GST_PIPELINE (pipeline));\n",
      "  bus_watch_id = gst_bus_add_watch (bus, bus_call, loop);\n",
      "  gst_object_unref (bus);\n",
      "\n",
      "  /* Set up the pipeline */\n",
      "  /* we add all elements into the pipeline */\n",
      "  if(prop.integrated) {\n",
      "    gst_bin_add_many (GST_BIN (pipeline),\n",
      "        source, h264parser, decoder, streammux, pgie,\n",
      "        nvvidconv, nvosd, transform, sink, NULL);\n",
      "  }\n",
      "  else {\n",
      "  gst_bin_add_many (GST_BIN (pipeline),\n",
      "      source, h264parser, decoder, streammux, pgie,\n",
      "      nvvidconv, nvosd, sink, NULL);\n",
      "  }\n",
      "\n",
      "  GstPad *sinkpad, *srcpad;\n",
      "  gchar pad_name_sink[16] = \"sink_0\";\n",
      "  gchar pad_name_src[16] = \"src\";\n",
      "\n",
      "  sinkpad = gst_element_get_request_pad (streammux, pad_name_sink);\n",
      "  if (!sinkpad) {\n",
      "    g_printerr (\"Streammux request sink pad failed. Exiting.\\n\");\n",
      "    return -1;\n",
      "  }\n",
      "\n",
      "  srcpad = gst_element_get_static_pad (decoder, pad_name_src);\n",
      "  if (!srcpad) {\n",
      "    g_printerr (\"Decoder request src pad failed. Exiting.\\n\");\n",
      "    return -1;\n",
      "  }\n",
      "\n",
      "  if (gst_pad_link (srcpad, sinkpad) != GST_PAD_LINK_OK) {\n",
      "      g_printerr (\"Failed to link decoder to stream muxer. Exiting.\\n\");\n",
      "      return -1;\n",
      "  }\n",
      "\n",
      "  gst_object_unref (sinkpad);\n",
      "  gst_object_unref (srcpad);\n",
      "\n",
      "  /* we link the elements together */\n",
      "  /* file-source -> h264-parser -> nvh264-decoder ->\n",
      "   * nvinfer -> nvvidconv -> nvosd -> video-renderer */\n",
      "\n",
      "  if (!gst_element_link_many (source, h264parser, decoder, NULL)) {\n",
      "    g_printerr (\"Elements could not be linked: 1. Exiting.\\n\");\n",
      "    return -1;\n",
      "  }\n",
      "\n",
      "  if(prop.integrated) {\n",
      "    if (!gst_element_link_many (streammux, pgie,\n",
      "        nvvidconv, nvosd, transform, sink, NULL)) {\n",
      "      g_printerr (\"Elements could not be linked: 2. Exiting.\\n\");\n",
      "      return -1;\n",
      "    }\n",
      "  }\n",
      "  else {\n",
      "    if (!gst_element_link_many (streammux, pgie,\n",
      "        nvvidconv, nvosd, sink, NULL)) {\n",
      "      g_printerr (\"Elements could not be linked: 2. Exiting.\\n\");\n",
      "      return -1;\n",
      "    }\n",
      "  }\n",
      "\n",
      "  /* Lets add probe to get informed of the meta data generated, we add probe to\n",
      "   * the sink pad of the osd element, since by that time, the buffer would have\n",
      "   * had got all the metadata. */\n",
      "  osd_sink_pad = gst_element_get_static_pad (nvosd, \"sink\");\n",
      "  if (!osd_sink_pad)\n",
      "    g_print (\"Unable to get sink pad\\n\");\n",
      "  else\n",
      "    gst_pad_add_probe (osd_sink_pad, GST_PAD_PROBE_TYPE_BUFFER,\n",
      "        osd_sink_pad_buffer_probe, NULL, NULL);\n",
      "  gst_object_unref (osd_sink_pad);\n",
      "\n",
      "  /* Set the pipeline to \"playing\" state */\n",
      "  g_print (\"Using file: %s\\n\", argv[1]);\n",
      "  gst_element_set_state (pipeline, GST_STATE_PLAYING);\n",
      "\n",
      "  /* Wait till pipeline encounters an error or EOS */\n",
      "  g_print (\"Running...\\n\");\n",
      "  g_main_loop_run (loop);\n",
      "\n",
      "  /* Out of the main loop, clean up nicely */\n",
      "  g_print (\"Returned, stopping playback\\n\");\n",
      "  gst_element_set_state (pipeline, GST_STATE_NULL);\n",
      "  g_print (\"Deleting pipeline\\n\");\n",
      "  gst_object_unref (GST_OBJECT (pipeline));\n",
      "  g_source_remove (bus_watch_id);\n",
      "  g_main_loop_unref (loop);\n",
      "  return 0;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat /opt/nvidia/deepstream/deepstream-6.1/sources/apps/sample_apps/deepstream-test1/deepstream_test1_app.c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
